{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "class EncoderParagraph(nn.Module):\n",
    "    \n",
    "    def __init__(self,word_size,word_dim, hidden_size, pretrained_word_embeds=None):\n",
    "        super(EncoderParagraph, self).__init__()\n",
    "        \n",
    "        self.word_size = word_size\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pretrained_word_embeds = pretrained_word_embeds\n",
    "        self.embedding = nn.Embedding(self.word_size,self.word_dim,padding_idx=0)\n",
    "        self.lstm = nn.LSTM(self.word_dim,self.hidden_size,batch_first = True,bidirectional=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.embedding(x)\n",
    "        out,hidden_cell = self.lstm(out)\n",
    "        return out,hidden_cell\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if PRE_TRAINED_EMBEDDING:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(self.pretrained_word_embeds))\n",
    "            if NON_TRAINABLE:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "            else:\n",
    "                self.embedding.weight.requires_grad = True\n",
    "        else:\n",
    "            init.xavier_uniform_(self.embedding.weight.data)\n",
    "            \n",
    "class EncoderSentence(nn.Module):\n",
    "    \n",
    "    def __init__(self,word_size,word_dim, hidden_size, pretrained_word_embeds=None):\n",
    "        super(EncoderSentence, self).__init__()\n",
    "        \n",
    "        self.word_size = word_size\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pretrained_word_embeds = pretrained_word_embeds\n",
    "        self.embedding = nn.Embedding(self.word_size,self.word_dim,padding_idx=0)\n",
    "        self.lstm = nn.LSTM(self.word_dim,self.hidden_size,batch_first = True,bidirectional=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.embedding(x)\n",
    "        out,hidden_cell = self.lstm(out)\n",
    "        return out,hidden_cell\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if PRE_TRAINED_EMBEDDING:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(self.pretrained_word_embeds))\n",
    "            if NON_TRAINABLE:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "            else:\n",
    "                self.embedding.weight.requires_grad = True\n",
    "        else:\n",
    "            init.xavier_uniform_(self.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_enc = EncoderParagraph(10,4,5)\n",
    "sen_enc = EncoderSentence(10,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an input tensor of random indices\n",
    "test_input1 = torch.randint(0, 9, (4,3), dtype=torch.long)\n",
    "test_input2 = torch.randint(0, 9, (4,6), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = par_enc(test_input1)\n",
    "c,d = sen_enc(test_input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 10])\n",
      "torch.Size([4, 6, 10])\n"
     ]
    }
   ],
   "source": [
    "print a.size()\n",
    "print c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 5])\n",
      "torch.Size([1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print b[0][0::2].size()\n",
    "print d[0][0::2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 5])\n",
      "torch.Size([1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print b[1][0::2].size()\n",
    "print d[1][0::2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = torch.cat((b[0][0::2],d[0][0::2]),2)\n",
    "f = torch.cat((b[1][0::2],d[1][0::2]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 10])\n",
      "torch.Size([1, 4, 10])\n"
     ]
    }
   ],
   "source": [
    "print e.size()\n",
    "print f.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1076, -0.2935,  0.0755,  0.0771,  0.2181,  0.0943,  0.0197,\n",
       "          -0.2198,  0.2790, -0.1438],\n",
       "         [ 0.0639, -0.1106, -0.0201,  0.1325, -0.0875, -0.0698,  0.0299,\n",
       "          -0.1304,  0.5169, -0.2540],\n",
       "         [ 0.1161, -0.2714,  0.0652,  0.0895,  0.2234,  0.0622, -0.0138,\n",
       "          -0.1512,  0.3889, -0.2338],\n",
       "         [ 0.0059, -0.1488,  0.0567,  0.1260,  0.0924,  0.0996, -0.0005,\n",
       "          -0.2134,  0.3472, -0.1267]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1076, -0.2935,  0.0755,  0.0771,  0.2181],\n",
       "         [ 0.0639, -0.1106, -0.0201,  0.1325, -0.0875],\n",
       "         [ 0.1161, -0.2714,  0.0652,  0.0895,  0.2234],\n",
       "         [ 0.0059, -0.1488,  0.0567,  0.1260,  0.0924]]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderLSTM(nn.Module):\n",
    "    def __init__(self, word_size,word_dim, hidden_size,max_length,pretrained_word_embeds=None):\n",
    "        super(AttnDecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.word_size = word_size\n",
    "        self.word_dim = word_dim\n",
    "        self.encoder_hidden_dim = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.word_size,self.word_dim,padding_idx=0)\n",
    "        self.attn = nn.Linear(self.word_dim+self.encoder_hidden_dim, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.word_dim+self.encoder_hidden_dim, self.word_dim)\n",
    "        #self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.word_dim,self.hidden_size,batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.word_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output1):\n",
    "        embedded = self.embedding(input)\n",
    "        #print embedded.squeeze(1).size(),hidden[0].squeeze(0).size()\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded.squeeze(1),hidden[0].squeeze(0)),1)), dim=1)\n",
    "        \n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        \n",
    "        # Apply Attention weights\n",
    "        #print attn_weights.size(),encoder_output1.size()\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_output1)\n",
    "        attn_applied = attn_applied.squeeze(1)\n",
    "        \n",
    "        # Prepare LSTM input tensor\n",
    "        attn_combined = torch.cat((embedded.squeeze(1), attn_applied), 1)\n",
    "\n",
    "        lstm_input = F.relu(self.attn_combine(attn_combined))\n",
    "        lstm_input = lstm_input.unsqueeze(1)\n",
    "        output, hidden = self.lstm(lstm_input, hidden)\n",
    "        output = F.log_softmax(self.out(output[:,0,:]), dim=1)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderLSTM(10,4,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input3 = torch.randint(0, 9, (4,1), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,q,r = decoder(test_input3,(e,f),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n",
      "torch.Size([1, 4, 10])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print p.size()\n",
    "print q[0].size()\n",
    "print r.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QuestionGeneration(nn.Module):\n",
    "    def __init__(self, para_encoder,sent_encoder, decoder):\n",
    "        super(QuestionGeneration, self).__init__()\n",
    "        \n",
    "        self.encoder1 = para_encoder\n",
    "        self.encoder2 = sent_encoder\n",
    "        self.decoder = decoder \n",
    "        \n",
    "        \n",
    "    def forward(self, para_src,sent_src, trg, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        #src = [batch size, sent len]\n",
    "        #trg = [batch size, sent len]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        max_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.word_size\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size,max_len, trg_vocab_size)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        out1, hidden_cell1 = self.encoder1(para_src)\n",
    "        out2, hidden_cell2 = self.encoder2(sent_src)\n",
    "        hidden = torch.cat((hidden_cell1[0][0::2],hidden_cell2[0][0::2]),dim=2)\n",
    "        cell = torch.cat((hidden_cell1[1][0::2],hidden_cell2[1][0::2]),dim=2)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[:,0]\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            input = input.unsqueeze(1)\n",
    "            output, (hidden, cell) = self.decoder(input, (hidden, cell),out2)\n",
    "            outputs[:,t,:] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            input = (trg[:,t] if teacher_force else top1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
