{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderSentence(nn.Module):\n",
    "    \n",
    "    def __init__(self,word_size,word_dim, hidden_size, pretrained_word_embeds=None, output_type = 'sum'):\n",
    "        super(EncoderSentence, self).__init__()\n",
    "        \n",
    "        self.output_type = output_type\n",
    "        self.word_size = word_size\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pretrained_word_embeds = pretrained_word_embeds\n",
    "        self.embedding = nn.Embedding(self.word_size,self.word_dim,padding_idx=0)\n",
    "        self.lstm = nn.LSTM(self.word_dim,self.hidden_size,batch_first = True,bidirectional=True)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def forward(self,x,input_lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths,batch_first=True)\n",
    "        outputs, hidden_cell = self.lstm(packed)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs,batch_first=True)\n",
    "        if self.output_type == 'sum':\n",
    "            outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        elif self.output_type =='concat':\n",
    "            outputs = torch.cat((outputs[:, :, :self.hidden_size], outputs[:, : ,self.hidden_size:]),dim=2)\n",
    "        else:\n",
    "            raise NotImplementedError \n",
    "        return outputs,hidden_cell\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if PRE_TRAINED_EMBEDDING or WORD2VEC_EMBEDDING :\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(self.pretrained_word_embeds))\n",
    "            if NON_TRAINABLE:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "            else:\n",
    "                self.embedding.weight.requires_grad = True\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_data_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([63, 45, 45, 45, 45, 45, 39, 38, 35, 35, 35, 35, 35, 35, 34, 34, 33, 33,\n",
       "        30, 30, 30, 25, 25, 25, 23, 22, 20, 17, 17, 14, 11,  9])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EncoderSentence(len(word_mapping)+1,WORD_DIM,128,pretrained_word_embeds,'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "e,f = enc(i[1],i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([54, 43, 41, 41, 41, 38, 37, 37, 37, 36, 36, 36, 36, 33, 30, 26, 26, 25,\n",
       "        23, 23, 21, 21, 21, 18, 18, 17, 17, 16, 16, 16, 15, 15])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0087, -0.1990,  0.0752,  ...,  0.0978,  0.0327,  0.0199],\n",
       "         [-0.0377, -0.0681,  0.0348,  ...,  0.0531, -0.0119, -0.0419],\n",
       "         [-0.0304,  0.0118,  0.0505,  ...,  0.0566, -0.0231, -0.0367],\n",
       "         ...,\n",
       "         [-0.0244,  0.0674,  0.0451,  ...,  0.0480, -0.0072, -0.0264],\n",
       "         [-0.0271,  0.0571,  0.0224,  ...,  0.0472,  0.0121, -0.0277],\n",
       "         [-0.0430,  0.0597,  0.0034,  ...,  0.0159,  0.0042, -0.0077]],\n",
       "\n",
       "        [[-0.0087, -0.1990,  0.0752,  ...,  0.0862,  0.0297,  0.0068],\n",
       "         [-0.0346, -0.0705,  0.0686,  ...,  0.0284, -0.0110, -0.0756],\n",
       "         [-0.0250,  0.0049,  0.0641,  ..., -0.0045, -0.0136, -0.0758],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0087, -0.1990,  0.0752,  ...,  0.1023,  0.0325,  0.0080],\n",
       "         [-0.0346, -0.0705,  0.0686,  ...,  0.0919, -0.0028, -0.0886],\n",
       "         [-0.1819, -0.1748,  0.0709,  ...,  0.1492,  0.0022, -0.0871],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0087, -0.1990,  0.0752,  ...,  0.1291,  0.0340,  0.0016],\n",
       "         [-0.1763, -0.2279,  0.0741,  ...,  0.1530, -0.0041, -0.0806],\n",
       "         [-0.0722, -0.0597,  0.0752,  ...,  0.0440,  0.0009, -0.0481],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0087, -0.1990,  0.0752,  ...,  0.0914,  0.0282,  0.0148],\n",
       "         [-0.0345, -0.0701,  0.0337,  ...,  0.0364, -0.0061, -0.0569],\n",
       "         [-0.0390,  0.0333,  0.0272,  ...,  0.0499, -0.0067, -0.0469],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0087, -0.1990,  0.0752,  ...,  0.1244,  0.0351,  0.0055],\n",
       "         [-0.1763, -0.2279,  0.0741,  ...,  0.1442, -0.0045, -0.0761],\n",
       "         [-0.0755, -0.0928,  0.0752,  ...,  0.0207, -0.0018, -0.0501],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
